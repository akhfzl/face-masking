{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9475319,"sourceType":"datasetVersion","datasetId":5762677},{"sourceId":9476050,"sourceType":"datasetVersion","datasetId":5763254}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd, numpy as np, matplotlib.pyplot as plt\nimport cv2 as cv\nfrom sklearn.cluster import KMeans\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\nfrom keras.models import Model\nfrom tensorflow.keras.regularizers import l2\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns, os\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization, Input, MaxPooling2D, Conv2D, GlobalAveragePooling2D\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, LearningRateScheduler\nfrom sklearn.model_selection import GridSearchCV\nimport keras_tuner as kt\nfrom keras_tuner import HyperModel","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:01.462048Z","iopub.execute_input":"2024-10-01T23:21:01.462627Z","iopub.status.idle":"2024-10-01T23:21:01.525588Z","shell.execute_reply.started":"2024-10-01T23:21:01.462593Z","shell.execute_reply":"2024-10-01T23:21:01.524760Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_random_images(generator, num_images=20):\n    # Get a batch of data from the generator\n    images, labels = next(generator)\n\n    # Get random indices for selecting images\n    random_indices = np.random.choice(images.shape[0], num_images, replace=False)\n\n    # Plot the selected images\n    fig, axs = plt.subplots(4, 5, figsize=(15, 12))\n    fig.suptitle('Random 20 Images from the Generator', fontsize=16)\n\n    for i, ax in enumerate(axs.flatten()):\n        index = random_indices[i]\n        image = images[index]\n        label = labels[index]\n\n        # Display the image\n        ax.imshow(image)\n        ax.set_title(f'Class: {np.argmax(label)}')\n        ax.axis('off')\n\n    plt.show()\n    \ndef count_images_per_class(generator):\n    class_counts = {class_name: 0 for class_name in generator.class_indices}\n    \n    for i in range(len(generator.classes)):\n        class_index = generator.classes[i] \n        class_name = list(generator.class_indices.keys())[class_index] \n        class_counts[class_name] += 1  \n\n    return class_counts\n\ndef visualize_per_class(categories, values):\n    colors = ['green', 'red', 'orange']\n    plt.bar(categories, values, color=colors)\n    plt.xlabel('Kategori')\n    plt.ylabel('Jumlah')\n    plt.title('Correct Counts Data')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:01.527304Z","iopub.execute_input":"2024-10-01T23:21:01.527678Z","iopub.status.idle":"2024-10-01T23:21:01.537484Z","shell.execute_reply.started":"2024-10-01T23:21:01.527636Z","shell.execute_reply":"2024-10-01T23:21:01.536603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths = '/kaggle/input/d/afthesis/result-preprocess-v2/new_result_v2'\noriginal_data = ImageDataGenerator(rescale=1./255)\nfull_data = original_data.flow_from_directory(paths, target_size = (224, 224), batch_size = 32, class_mode=\"categorical\", shuffle=False)\ntrain_class_counts = count_images_per_class(full_data)\nvisualize_per_class(train_class_counts.keys(), train_class_counts.values())","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:01.538398Z","iopub.execute_input":"2024-10-01T23:21:01.538688Z","iopub.status.idle":"2024-10-01T23:21:01.975315Z","shell.execute_reply.started":"2024-10-01T23:21:01.538658Z","shell.execute_reply":"2024-10-01T23:21:01.974460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_data = ImageDataGenerator(rescale=1./255)\ndata_fully = original_data.flow_from_directory(paths, target_size = (224, 224), batch_size = 32, class_mode=\"categorical\", shuffle=False)\nfilenames = data_fully.filenames\nlabels = data_fully.labels\nclass_mapping = {value: str(key) for key, value in data_fully.class_indices.items()}\nlabels = [class_mapping[label] for label in labels]\nfilenames[:5], labels[:5]","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:01.977111Z","iopub.execute_input":"2024-10-01T23:21:01.977399Z","iopub.status.idle":"2024-10-01T23:21:02.033171Z","shell.execute_reply.started":"2024-10-01T23:21:01.977368Z","shell.execute_reply":"2024-10-01T23:21:02.032335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_filenames, test_filenames, train_labels, test_labels = train_test_split(\n    filenames, labels, test_size=0.2, random_state=42)\nval_filenames, test_filenames, val_labels, test_labels = train_test_split(\n    test_filenames, test_labels, test_size=0.5, random_state=42)\n\n# Create DataFrames for training and testing\ntrain_df = pd.DataFrame({'filename': train_filenames, 'class': train_labels})\nval_df = pd.DataFrame({'filename': val_filenames, 'class': val_labels})\ntest_df = pd.DataFrame({'filename': test_filenames, 'class': test_labels})\n\n# Create separate generators for training and testing using flow_from_dataframe\ntrain_data = original_data.flow_from_dataframe(train_df, directory=paths, target_size=(224, 224),\n                                           batch_size=32, class_mode=\"categorical\",\n                                           shuffle=False, seed=42)\n\nval_data = original_data.flow_from_dataframe(val_df, directory=paths, target_size=(224, 224),\n                                          batch_size=32, class_mode=\"categorical\",\n                                          shuffle=False)\n\ntest_data = original_data.flow_from_dataframe(test_df, directory=paths, target_size=(224, 224),\n                                          batch_size=32, class_mode=\"categorical\",\n                                          shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:02.034312Z","iopub.execute_input":"2024-10-01T23:21:02.034683Z","iopub.status.idle":"2024-10-01T23:21:02.088571Z","shell.execute_reply.started":"2024-10-01T23:21:02.034642Z","shell.execute_reply":"2024-10-01T23:21:02.087721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_images(original, segment):\n    # Create a figure to display the images\n    plt.figure(figsize=(15, 5))\n\n    plt.subplot(1, 3, 1)\n    plt.imshow(original) \n    plt.title('Original Image')\n    plt.axis('off')\n\n    plt.subplot(1, 3, 3)\n    plt.imshow(segment, cmap='gray')\n    plt.title('Segmentation with KNN')\n    plt.axis('off')\n\n    # Show\n    plt.tight_layout()\n    plt.show()\n\ndef load_image(image_path):\n    img = cv.imread(image_path)\n    img = cv.cvtColor(img, cv.COLOR_BGR2GRAY) \n    return img\n\ndef segment_images_kmean(image, n_clusters):\n    pixels = image.reshape(-1, 1)  \n\n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n    kmeans.fit(pixels)\n\n    labels = kmeans.labels_\n    centers = kmeans.cluster_centers_.astype(int) \n\n    segmented_image = centers[labels].reshape(image.shape)  \n    return segmented_image\n\ndef image_preprocessing(image_path):\n    img = load_image(image_path)\n    img_segmented = segment_images_kmean(img, 5)\n    \n    return img_segmented\n\ndef preprocess_and_save_images(input_dir, filenames, classes, output_dir):\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    \n    for i in range(len(classes)):\n        myclass = 'cadar' if classes[i] == 0 else 'masking' if classes[i] == 1 else 'unmasking'\n        class_path = os.path.join(input_dir, myclass)\n        if os.path.isdir(class_path): \n            output_class_path = os.path.join(output_dir, myclass)\n            os.makedirs(output_class_path, exist_ok=True)  \n            \n            img_path = os.path.join(input_dir, filenames[i])\n            # print(img_path)\n            preprocessed_img = image_preprocessing(img_path)\n\n            # Save\n            output_img_path = os.path.join(output_dir, filenames[i])\n            cv.imwrite(output_img_path, preprocessed_img)\n                \n    print(f\"Preprocessing complete. Preprocessed images saved in {output_dir}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:02.089701Z","iopub.execute_input":"2024-10-01T23:21:02.090045Z","iopub.status.idle":"2024-10-01T23:21:02.102861Z","shell.execute_reply.started":"2024-10-01T23:21:02.090002Z","shell.execute_reply":"2024-10-01T23:21:02.101918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_dir = '/kaggle/working/new_result_v2'\nimg_dir = '/kaggle/input/d/afthesis/result-preprocess-v2/new_result_v2'\npreprocess_and_save_images(img_dir, val_data.filenames, val_data.classes, output_dir)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:02.103920Z","iopub.execute_input":"2024-10-01T23:21:02.104223Z","iopub.status.idle":"2024-10-01T23:21:42.986584Z","shell.execute_reply.started":"2024-10-01T23:21:02.104193Z","shell.execute_reply":"2024-10-01T23:21:42.985697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import shutil\n# shutil.make_archive('/kaggle/working/test_new_result_v2', 'zip', '/kaggle/working/test_new_result_v2')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:42.987762Z","iopub.execute_input":"2024-10-01T23:21:42.988067Z","iopub.status.idle":"2024-10-01T23:21:42.991702Z","shell.execute_reply.started":"2024-10-01T23:21:42.988033Z","shell.execute_reply":"2024-10-01T23:21:42.990853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_dir = '/kaggle/working/new_result_v2'\nfull_val_original = ImageDataGenerator(rescale=1./255)\n\n# Menggunakan flow_from_directory untuk mendapatkan class names\nval_fully = full_val_original.flow_from_directory(\n    val_dir,\n    target_size=(224, 224),\n    batch_size=32,\n    class_mode=\"categorical\",\n    shuffle=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:42.992714Z","iopub.execute_input":"2024-10-01T23:21:42.992986Z","iopub.status.idle":"2024-10-01T23:21:43.009927Z","shell.execute_reply.started":"2024-10-01T23:21:42.992956Z","shell.execute_reply":"2024-10-01T23:21:43.009080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.image_shape","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:43.013803Z","iopub.execute_input":"2024-10-01T23:21:43.014130Z","iopub.status.idle":"2024-10-01T23:21:43.019576Z","shell.execute_reply.started":"2024-10-01T23:21:43.014100Z","shell.execute_reply":"2024-10-01T23:21:43.018725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_lr = 0.0001\nmin_lr = 0.000001\nmax_lr = 0.001\nrampup_epochs = 5\nsustain_epochs = 0\nexp_decay = 0.8\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n\n# Define the scheduling function\ndef schedule(epoch):\n  def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n    if epoch < rampup_epochs:\n      lr = (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n    elif epoch < rampup_epochs + sustain_epochs:\n      lr = max_lr\n    else:\n      lr = (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n    return lr\n  return lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay)\n    \nscheduler_lr = LearningRateScheduler(schedule, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:43.020694Z","iopub.execute_input":"2024-10-01T23:21:43.020971Z","iopub.status.idle":"2024-10-01T23:21:43.030055Z","shell.execute_reply.started":"2024-10-01T23:21:43.020941Z","shell.execute_reply":"2024-10-01T23:21:43.029342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:43.031047Z","iopub.execute_input":"2024-10-01T23:21:43.031355Z","iopub.status.idle":"2024-10-01T23:21:43.241386Z","shell.execute_reply.started":"2024-10-01T23:21:43.031325Z","shell.execute_reply":"2024-10-01T23:21:43.240428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With adaptif learning","metadata":{}},{"cell_type":"code","source":"def modeling(img_width, img_height, training, validation):\n    # Distribution strategy\n    strategy = tf.distribute.MirroredStrategy()\n\n    with strategy.scope():\n        # Input layer\n        inputs = Input(shape=(img_width, img_height, 3))\n\n        # Convolution block 1\n        conv1 = Conv2D(filters=32, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(inputs)\n        conv1 = BatchNormalization()(conv1)\n        conv1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n        # Convolution block 2\n        conv2 = Conv2D(filters=64, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(conv1)\n        conv2 = BatchNormalization()(conv2)\n        conv2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n        # Convolution block 3\n        conv3 = Conv2D(filters=128, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(conv2)\n        conv3 = BatchNormalization()(conv3)\n        conv3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n        # Convolution block 4 with global pooling\n        conv4 = Conv2D(filters=256, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(conv3)\n        conv4 = BatchNormalization()(conv4)\n        conv4 = GlobalAveragePooling2D()(conv4)  # Global pooling instead of MaxPooling2D\n\n        # Flatten and dense layers\n        x = Flatten()(conv4)\n        x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n        x = Dropout(0.5)(x)\n        x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n        x = Dropout(0.5)(x)\n        x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n        x = Dropout(0.5)(x)\n        outputs = Dense(3, activation='softmax')(x)  # Assuming 3 classes\n\n        # Build and compile model\n        model = Model(inputs=inputs, outputs=outputs)\n        model.summary()\n\n        # Compile the model\n        optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n        # Add early stopping and learning rate scheduler\n        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n\n        # Train model with augmented data\n        history = model.fit(training, validation_data=validation, epochs=100, callbacks=[early_stopping, lr_scheduler])\n        \n        return history","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:43.242711Z","iopub.execute_input":"2024-10-01T23:21:43.243084Z","iopub.status.idle":"2024-10-01T23:21:43.258253Z","shell.execute_reply.started":"2024-10-01T23:21:43.243041Z","shell.execute_reply":"2024-10-01T23:21:43.257347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = modeling(224, 224, train_data, val_fully)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:21:43.259271Z","iopub.execute_input":"2024-10-01T23:21:43.259601Z","iopub.status.idle":"2024-10-01T23:25:14.360419Z","shell.execute_reply.started":"2024-10-01T23:21:43.259569Z","shell.execute_reply":"2024-10-01T23:25:14.359632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def showAllValueOfHistory(history, epochs_range):\n    epochs_range = list(range(epochs_range))\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    plt.figure(figsize=(16, 8))\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs_range, accuracy, label='Training Accuracy')\n    plt.plot(epochs_range, val_accuracy, label='Validation Accuracy')\n    plt.legend(loc='lower right')\n    plt.title('Training & Validation Accuracy')\n\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs_range, loss, label='Training Loss')\n    plt.plot(epochs_range, val_loss, label='Validation Loss')\n    plt.legend(loc='upper right')\n    plt.title('Training & Validation Loss')\n    return plt.show()\n\nshowAllValueOfHistory(history, 51)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:25:53.904438Z","iopub.execute_input":"2024-10-01T23:25:53.905174Z","iopub.status.idle":"2024-10-01T23:25:54.356828Z","shell.execute_reply.started":"2024-10-01T23:25:53.905135Z","shell.execute_reply":"2024-10-01T23:25:54.355906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.model.save('/kaggle/working/model_30_with_adaptif.h5')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:26:07.441764Z","iopub.execute_input":"2024-10-01T23:26:07.442143Z","iopub.status.idle":"2024-10-01T23:26:07.528098Z","shell.execute_reply.started":"2024-10-01T23:26:07.442104Z","shell.execute_reply":"2024-10-01T23:26:07.527377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"without adaptif learning","metadata":{}},{"cell_type":"code","source":"def modeling(img_width, img_height, training, validation):\n    # Distribution strategy\n    strategy = tf.distribute.MirroredStrategy()\n\n    with strategy.scope():\n        # Input layer\n        inputs = Input(shape=(img_width, img_height, 3))\n\n        # Convolution block 1\n        conv1 = Conv2D(filters=32, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(inputs)\n        conv1 = BatchNormalization()(conv1)\n        conv1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n        # Convolution block 2\n        conv2 = Conv2D(filters=64, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(conv1)\n        conv2 = BatchNormalization()(conv2)\n        conv2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n        # Convolution block 3\n        conv3 = Conv2D(filters=128, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(conv2)\n        conv3 = BatchNormalization()(conv3)\n        conv3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n        # Convolution block 4 with global pooling\n        conv4 = Conv2D(filters=256, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(conv3)\n        conv4 = BatchNormalization()(conv4)\n        conv4 = GlobalAveragePooling2D()(conv4)  # Global pooling instead of MaxPooling2D\n\n        # Flatten and dense layers\n        x = Flatten()(conv4)\n        x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n        x = Dropout(0.5)(x)\n        x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n        x = Dropout(0.5)(x)\n        x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n        x = Dropout(0.5)(x)\n        outputs = Dense(3, activation='softmax')(x)  # Assuming 3 classes\n\n        # Build and compile model\n        model = Model(inputs=inputs, outputs=outputs)\n        model.summary()\n\n        # Compile the model\n        optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n        # Add early stopping and learning rate scheduler\n        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n\n        # Train model with augmented data\n        history = model.fit(training, validation_data=validation, epochs=100, callbacks=[early_stopping])\n        \n        return history","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:26:15.612024Z","iopub.execute_input":"2024-10-01T23:26:15.612406Z","iopub.status.idle":"2024-10-01T23:26:15.627621Z","shell.execute_reply.started":"2024-10-01T23:26:15.612368Z","shell.execute_reply":"2024-10-01T23:26:15.626616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = modeling(224, 224, train_data, val_fully)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:26:18.699926Z","iopub.execute_input":"2024-10-01T23:26:18.700304Z","iopub.status.idle":"2024-10-01T23:29:25.091242Z","shell.execute_reply.started":"2024-10-01T23:26:18.700264Z","shell.execute_reply":"2024-10-01T23:29:25.090399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"showAllValueOfHistory(history, 47)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:29:36.143306Z","iopub.execute_input":"2024-10-01T23:29:36.144439Z","iopub.status.idle":"2024-10-01T23:29:36.655067Z","shell.execute_reply.started":"2024-10-01T23:29:36.144382Z","shell.execute_reply":"2024-10-01T23:29:36.654108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history.model.save('/kaggle/working/model_30_without_adaptif.h5')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:29:42.150358Z","iopub.execute_input":"2024-10-01T23:29:42.151216Z","iopub.status.idle":"2024-10-01T23:29:42.229944Z","shell.execute_reply.started":"2024-10-01T23:29:42.151157Z","shell.execute_reply":"2024-10-01T23:29:42.229015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"with adaptif learning and parameter tuning","metadata":{}},{"cell_type":"code","source":"# Optimizer\t\t\t: adam, rmsprop\n# Batch Size\t\t: 16, 32, 64\n# Dropout\t\t\t: 0.0, 0.3, 0.5","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:25:16.042611Z","iopub.status.idle":"2024-10-01T23:25:16.042948Z","shell.execute_reply.started":"2024-10-01T23:25:16.042771Z","shell.execute_reply":"2024-10-01T23:25:16.042788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MaskDetectionHyperModel(HyperModel):\n    def __init__(self, input_shape):\n        self.input_shape = input_shape\n\n    def build(self, hp):\n        inputs = Input(shape=self.input_shape)\n\n        # Convolution block 1\n        conv1 = Conv2D(32, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(inputs)\n        conv1 = BatchNormalization()(conv1)\n        conv1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n        # Convolution block 2\n        conv2 = Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(conv1)\n        conv2 = BatchNormalization()(conv2)\n        conv2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n        # Convolution block 3\n        conv3 = Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(conv2)\n        conv3 = BatchNormalization()(conv3)\n        conv3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n        # Convolution block 4 with global pooling\n        conv4 = Conv2D(256, (3, 3), activation='relu', kernel_regularizer=l2(0.001))(conv3)\n        conv4 = BatchNormalization()(conv4)\n        conv4 = GlobalAveragePooling2D()(conv4)\n\n        # Flatten and dense layers\n        x = Flatten()(conv4)\n        x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n        \n        # Tunable dropout\n        dropout_rate = hp.Choice('dropout', values=[0.0, 0.3, 0.5])\n        x = Dropout(dropout_rate)(x)\n        \n        x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n        x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n        outputs = Dense(3, activation='softmax')(x)\n\n        model = Model(inputs=inputs, outputs=outputs)\n\n        # Tunable optimizer\n        optimizer_choice = hp.Choice('optimizer', values=['adam', 'rmsprop'])\n        if optimizer_choice == 'adam':\n            optimizer = Adam(learning_rate=1e-3)\n        else:\n            optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-3)\n\n        model.compile(\n            optimizer=optimizer,\n            loss='categorical_crossentropy',\n            metrics=['accuracy']\n        )\n\n        return model","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:29:54.912094Z","iopub.execute_input":"2024-10-01T23:29:54.913018Z","iopub.status.idle":"2024-10-01T23:29:54.926926Z","shell.execute_reply.started":"2024-10-01T23:29:54.912975Z","shell.execute_reply":"2024-10-01T23:29:54.926036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tune_model(train_data, val_data, project_name='mask_detection_tuning'):\n    tuner = kt.RandomSearch(\n        MaskDetectionHyperModel(input_shape=(224, 224, 3)),\n        objective='val_accuracy',\n        max_trials=10,\n        executions_per_trial=1,\n        directory='my_dir',\n        project_name=project_name\n    )\n\n    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\n    # Tunable batch size\n    batch_sizes = [16, 32, 64]\n    best_val_accuracy = 0\n    best_batch_size = None\n    best_hps = None\n\n    for batch_size in batch_sizes:\n        tuner.search(train_data,\n                     validation_data=val_data,\n                     epochs=10,\n                     batch_size=batch_size,\n                     callbacks=[stop_early])\n        \n        hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n        model = tuner.hypermodel.build(hps)\n        history = model.fit(train_data, validation_data=val_data, epochs=10, batch_size=batch_size)\n        val_accuracy = max(history.history['val_accuracy'])\n        \n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n            best_batch_size = batch_size\n            best_hps = hps\n\n    print(f\"\"\"\n    The hyperparameter search is complete. The optimal hyperparameters are:\n    Optimizer: {best_hps.get('optimizer')}\n    Dropout rate: {best_hps.get('dropout')}\n    Batch size: {best_batch_size}\n    Best validation accuracy: {best_val_accuracy}\n    \"\"\")\n\n    return best_hps, best_batch_size, tuner","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:29:58.026383Z","iopub.execute_input":"2024-10-01T23:29:58.026794Z","iopub.status.idle":"2024-10-01T23:29:58.036912Z","shell.execute_reply.started":"2024-10-01T23:29:58.026739Z","shell.execute_reply":"2024-10-01T23:29:58.035915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('without adaptif')\nbest_hps, best_batch_size, tuner = tune_model(train_data, val_fully)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:30:02.322841Z","iopub.execute_input":"2024-10-01T23:30:02.323530Z","iopub.status.idle":"2024-10-01T23:35:34.393580Z","shell.execute_reply.started":"2024-10-01T23:30:02.323488Z","shell.execute_reply":"2024-10-01T23:35:34.391117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def modeling(img_width, img_height, training, validation):\n    # Distribution strategy\n    strategy = tf.distribute.MirroredStrategy()\n\n    with strategy.scope():\n        # Input layer\n        inputs = Input(shape=(img_width, img_height, 3))\n\n        # Convolution block 1\n        conv1 = Conv2D(filters=32, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(inputs)\n        conv1 = BatchNormalization()(conv1)\n        conv1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n        # Convolution block 2\n        conv2 = Conv2D(filters=64, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(conv1)\n        conv2 = BatchNormalization()(conv2)\n        conv2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n        # Convolution block 3\n        conv3 = Conv2D(filters=128, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(conv2)\n        conv3 = BatchNormalization()(conv3)\n        conv3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n        # Convolution block 4 with global pooling\n        conv4 = Conv2D(filters=256, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(conv3)\n        conv4 = BatchNormalization()(conv4)\n        conv4 = GlobalAveragePooling2D()(conv4)  # Global pooling instead of MaxPooling2D\n\n        # Flatten and dense layers\n        x = Flatten()(conv4)\n        x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n        x = Dropout(0.5)(x)\n        x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n        x = Dropout(0.5)(x)\n        x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n        x = Dropout(0.5)(x)\n        outputs = Dense(3, activation='softmax')(x)  # Assuming 3 classes\n\n        # Build and compile model\n        model = Model(inputs=inputs, outputs=outputs)\n        model.summary()\n\n        # Compile the model\n        optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)\n        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n        # Add early stopping and learning rate scheduler\n        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n\n        # Train model with augmented data\n        history = model.fit(training, validation_data=validation, epochs=100, batch_size=16, callbacks=[early_stopping])\n        \n        return history","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:38:00.598252Z","iopub.execute_input":"2024-10-01T23:38:00.598636Z","iopub.status.idle":"2024-10-01T23:38:00.614634Z","shell.execute_reply.started":"2024-10-01T23:38:00.598598Z","shell.execute_reply":"2024-10-01T23:38:00.613792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = modeling(224, 224, train_data, val_fully)\nhistory.model.save('/kaggle/working/model_30_without_adaptif_tuning.h5')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:38:02.155558Z","iopub.execute_input":"2024-10-01T23:38:02.155934Z","iopub.status.idle":"2024-10-01T23:40:46.437294Z","shell.execute_reply.started":"2024-10-01T23:38:02.155899Z","shell.execute_reply":"2024-10-01T23:40:46.436510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epoch = len(history.history['loss'])\nshowAllValueOfHistory(history, num_epoch)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:40:46.438844Z","iopub.execute_input":"2024-10-01T23:40:46.439149Z","iopub.status.idle":"2024-10-01T23:40:46.950483Z","shell.execute_reply.started":"2024-10-01T23:40:46.439115Z","shell.execute_reply":"2024-10-01T23:40:46.949568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tune_model(train_data, val_data, project_name='mask_detection_tuning'):\n    tuner = kt.RandomSearch(\n        MaskDetectionHyperModel(input_shape=(224, 224, 3)),\n        objective='val_accuracy',\n        max_trials=10,\n        executions_per_trial=1,\n        directory='my_dir',\n        project_name=project_name\n    )\n\n    stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n\n    # Tunable batch size\n    batch_sizes = [16, 32, 64]\n    best_val_accuracy = 0\n    best_batch_size = None\n    best_hps = None\n    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n    \n    for batch_size in batch_sizes:\n        tuner.search(train_data,\n                     validation_data=val_data,\n                     epochs=10,\n                     batch_size=batch_size,\n                     callbacks=[stop_early, lr_scheduler])\n        \n        hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n        model = tuner.hypermodel.build(hps)\n        history = model.fit(train_data, validation_data=val_data, epochs=10, batch_size=batch_size)\n        val_accuracy = max(history.history['val_accuracy'])\n        \n        if val_accuracy > best_val_accuracy:\n            best_val_accuracy = val_accuracy\n            best_batch_size = batch_size\n            best_hps = hps\n\n    print(f\"\"\"\n    The hyperparameter search is complete. The optimal hyperparameters are:\n    Optimizer: {best_hps.get('optimizer')}\n    Dropout rate: {best_hps.get('dropout')}\n    Batch size: {best_batch_size}\n    Best validation accuracy: {best_val_accuracy}\n    \"\"\")\n\n    return best_hps, best_batch_size, tuner","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:25:16.054443Z","iopub.status.idle":"2024-10-01T23:25:16.054837Z","shell.execute_reply.started":"2024-10-01T23:25:16.054656Z","shell.execute_reply":"2024-10-01T23:25:16.054676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('with adaptif')\nbest_hps, best_batch_size, tuner = tune_model(train_data, val_fully)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:25:16.055768Z","iopub.status.idle":"2024-10-01T23:25:16.056114Z","shell.execute_reply.started":"2024-10-01T23:25:16.055936Z","shell.execute_reply":"2024-10-01T23:25:16.055954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def modeling(img_width, img_height, training, validation):\n    # Distribution strategy\n    strategy = tf.distribute.MirroredStrategy()\n\n    with strategy.scope():\n        # Input layer\n        inputs = Input(shape=(img_width, img_height, 3))\n\n        # Convolution block 1\n        conv1 = Conv2D(filters=32, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(inputs)\n        conv1 = BatchNormalization()(conv1)\n        conv1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n\n        # Convolution block 2\n        conv2 = Conv2D(filters=64, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(conv1)\n        conv2 = BatchNormalization()(conv2)\n        conv2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n\n        # Convolution block 3\n        conv3 = Conv2D(filters=128, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(conv2)\n        conv3 = BatchNormalization()(conv3)\n        conv3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n\n        # Convolution block 4 with global pooling\n        conv4 = Conv2D(filters=256, kernel_size=(3, 3), strides=(2,2), activation='relu', kernel_regularizer=l2(0.001))(conv3)\n        conv4 = BatchNormalization()(conv4)\n        conv4 = GlobalAveragePooling2D()(conv4)  # Global pooling instead of MaxPooling2D\n\n        # Flatten and dense layers\n        x = Flatten()(conv4)\n        x = Dense(256, activation='relu', kernel_regularizer=l2(0.001))(x)\n        x = Dropout(0.5)(x)\n        x = Dense(128, activation='relu', kernel_regularizer=l2(0.001))(x)\n        x = Dropout(0.5)(x)\n        x = Dense(64, activation='relu', kernel_regularizer=l2(0.001))(x)\n        x = Dropout(0.5)(x)\n        outputs = Dense(3, activation='softmax')(x)  # Assuming 3 classes\n\n        # Build and compile model\n        model = Model(inputs=inputs, outputs=outputs)\n        model.summary()\n\n        # Compile the model\n        optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001)\n        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n\n        # Add early stopping and learning rate scheduler\n        early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n        lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n\n        # Train model with augmented data\n        history = model.fit(training, validation_data=validation, epochs=100, batch_size=64, callbacks=[early_stopping, lr_scheduler])\n        \n        return history","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:40:46.951790Z","iopub.execute_input":"2024-10-01T23:40:46.952097Z","iopub.status.idle":"2024-10-01T23:40:46.966434Z","shell.execute_reply.started":"2024-10-01T23:40:46.952064Z","shell.execute_reply":"2024-10-01T23:40:46.965583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = modeling(224, 224, train_data, val_fully)\nhistory.model.save('/kaggle/working/model_30_with_adaptif_tuning.h5')","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:40:46.968355Z","iopub.execute_input":"2024-10-01T23:40:46.968742Z","iopub.status.idle":"2024-10-01T23:43:42.401659Z","shell.execute_reply.started":"2024-10-01T23:40:46.968709Z","shell.execute_reply":"2024-10-01T23:43:42.400882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_epoch = len(history.history['loss'])\nshowAllValueOfHistory(history, num_epoch)","metadata":{"execution":{"iopub.status.busy":"2024-10-01T23:44:35.259877Z","iopub.execute_input":"2024-10-01T23:44:35.260257Z","iopub.status.idle":"2024-10-01T23:44:35.723542Z","shell.execute_reply.started":"2024-10-01T23:44:35.260220Z","shell.execute_reply":"2024-10-01T23:44:35.722604Z"},"trusted":true},"execution_count":null,"outputs":[]}]}